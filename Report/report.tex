\documentclass[11pt]{article}
\usepackage{theme}
\usepackage{shortcuts}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage[
style=ieee,
]
{biblatex}
\addbibresource{ref.bib}

% Document parameters
% Document title
\title{Mini-Project (ML for Time Series) - MVA 2023/2024}
\author{
Mathis Reymond \email{mathis.reymond74@gmail.com} \\ % student 1
Inès Vati \email{ines.vati@eleves.enpc.fr} % student 2
}

\begin{document}
\maketitle

% \paragraph{What is expected for these mini-projects?}
% The goal of the exercise is to read (and understand) a research article, implement it (or find an implementation), test it on real data and comment on the results obtained.
% Depending on the articles, the task will not always be the same: some articles are more theoretical or complex, others are in the direct line of the course, etc... It is therefore important to balance the exercise according to the article. For example, if you have reused an existing implementation, it is obvious that you will have to develop in a more detailed way the analysis of the results, the influence of the parameters etc... Do not hesitate to contact us by email if you wish to be guided.

% \paragraph{The report}
%  The report must be at most FIVE pages and use this template (excluding references). If needed, additional images and tables can be put in Appendix, but must be discussed in the main document. The report must contain a precise description of the work done, a description of the method, and the results of your tests. Please do not include source code! The report must clearly show the elements that you have done yourself and those that you have reused only, as well as the distribution of tasks within the team (see detailed plan below.)
 
%  \paragraph{The source code}
% In addition to this report, you will have to send us a Python notebook allowing to launch the code and to test it on data. For the data, you can find it on standard sites like Kaggle, or the site https://timeseriesclassification.com/ which contains a lot of signals!


% \paragraph{The oral presentations}
% They will last 10 minutes followed by 5 minutes of questions. The plan of the defense is the same as the one of the report: presentation of the work done, description of the method and analysis of the results.


% \paragraph{Deadlines}
% Two sessions will be available :
% \begin{itemize}
%  \item \textbf{Session 1}
%  \begin{itemize}
%   \item Deadline for report: December 18th (23:59)
%   \item Oral presentations: December 20th and 22th (precise times TBA)
%  \end{itemize}
% \end{itemize}

\section{Introduction and contributions}

% \blue{The Introduction section (indicative length : less than 1 page) should detail the scientific context of the article you chose, as well as the task that you want to solve (especially if you apply it on novel data). \textbf{The last paragraph of the introduction must contain the following information}:
% \begin{itemize}
%     \item Repartition of work between the two students
%     \item Use of available source code or not, percentage of the source code that has been reused, etc.
%     \item Use of existing experiments or new experiments (e.g. test of the influence of parameter that was not conducted in the original article, application of the method on a novel task/data set etc.)
%     \item Improvement on the original method (e.g. new pre/post processing steps, grid search for optimal parameters etc.)
% \end{itemize}}

The article at hand focuses on reviewing the current literature regarding the use of Graph Signal Processing (GSP) methods applied to brain graphs obtained from functional imaging techniques. Within this framework, graph representations illustrate brain regions as nodes and depict connections—be they functional or structural—as edges. This approach, viewing the brain through graphs, holds significance in connectomics and the broader field of network neuroscience. It facilitates the correlation between structural neural connections and the functional connectivity, even extending to behavioral observations.

Authors introduce a Fourier paradigm adapted to graph, including a Graph Fourier Transform (GFT) and graph filters. It allows the decomposition of brain signals based on spatial variability relative to the structure of the brain network. Additionally, they introduce signal surrogate generation, notably to assess significance of their results. They lead two experiments. In the first one, subjects perform a classic Navon switching task : they visualize big symbols made of smaller symbols (as big cross made of small circles). Depending on the colour of the small symbols, participants are asked to report either the shape of small or big symbols. Naturally, the response time is increased when the task switch, which allows defining what's called a switch cost. Using GSP tools, authors have shown that having isolated brain regions highly activated is positively correlated with high switch cost.

Authors provide no code. We wrote our own code for the experiments we conducted. Inès focused on graph surrogates and performed the experiment described in \ref{excursion_results}. Mathis performed on the experiment described in \ref{subsec:classification_results}. We state an equal contribution for the rest of the work carried out. Our code is available on \href{https://github.com/InesVATI/TimeSeries-GraphSignalProcessing}{GitHub}.

Along with qualitative remarks, our contribution lies in the three experiments we conducted. As neither code nor data used in the paper were available, we found another dataset, BOLD5000 \cite{chang_bold5000_2019}, on which we performed experiments using the tools introduced in the article.


\input{content/method}
\input{content/data}

\input{content/results}

\printbibliography

\appendix
\appendixpage % ajoute par defaut le titre "Appendices" au dessus de la première annexe
\input{appendices/appendice_fourier_transform}
\input{appendices/appendice_data}
\input{appendices/appendice_excursions}
\input{appendices/classification_results}

\end{document}
